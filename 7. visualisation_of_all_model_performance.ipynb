{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of All Trained Models\n",
    "\n",
    "This notebook is meant for you to be able to run all our pretrained models in the final_models folder and see the difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first import all necessary libraries:\n",
    "\n",
    "# Matplotlib\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MISC\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will define all of the different models and load them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_pt(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTM_pt, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # # LayerNorm applied to the hidden state\n",
    "        # self.layer_norm = torch.nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.randn(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.randn(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Apply LayerNorm to the output of the LSTM\n",
    "        # out = self.layer_norm(out)\n",
    "\n",
    "        # Pass only the last timestep's output to the FC layer\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "import random\n",
    "\n",
    "# Define the model parameters\n",
    "input_size = 8\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "output_size = 3\n",
    "num_epochs = 300\n",
    "learning_rate = 0.01\n",
    "\n",
    "LSTM_model = LSTM_pt(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "LSTM_model.load_state_dict(torch.load('./final_models/LSTM.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_pt(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(BiLSTM_pt, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.num_directions = 2  # Since it's bidirectional\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2, output_dim)  # Fix here\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.randn(self.layer_dim * self.num_directions, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.randn(self.layer_dim * self.num_directions, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Pass only the last timestep's output to the FC layer\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "input_size = 8\n",
    "hidden_size = 256\n",
    "num_layers = 2 # Can be changed to stack multiple LSTM layers!\n",
    "output_size = 3\n",
    "\n",
    "Bi_LSTM_model = BiLSTM_pt(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "Bi_LSTM_model.load_state_dict(torch.load('./final_models/Bi_LSTM.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Encoder-Decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # print(\"Encoder's input size: \", input_size)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Passing the input sequence through the LSTM\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(inputs)\n",
    "        # print(\"encoder output size: \", output.shape)\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate=0.3):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Implementing Prof Idea\n",
    "        self.linear1 = nn.Linear(hidden_size, 1)\n",
    "        self.linearsub1 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.linearsub2 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x, hidden,target=None):\n",
    "        outputs = []\n",
    "        decoder_input = x\n",
    "        \n",
    "        # First LSTM layer\n",
    "        y1, hidden1 = self.lstm(decoder_input, hidden)\n",
    "        y1 = self.dropout(y1)\n",
    "        linear_y1 = self.linear1(y1)\n",
    "        linear_y1 = linear_y1.mean(dim=1, keepdim=True)\n",
    "        linear_suby1 = self.linearsub1(y1)\n",
    "\n",
    "        # Second LSTM layer\n",
    "        y2, hidden2 = self.lstm(linear_suby1, hidden1)\n",
    "        y2 = self.dropout(y2)\n",
    "        linear_y2 = self.linear2(y2)\n",
    "        linear_suby2 = self.linearsub1(y2)\n",
    "        linear_y2 = linear_y2.mean(dim=1, keepdim=True)\n",
    "\n",
    "        y3, hidden3 = self.lstm(linear_suby2, hidden2)\n",
    "        y3 = self.dropout(y3)\n",
    "        linear_y3 = self.linear3(y3)\n",
    "        linear_y3 = linear_y3.mean(dim=1, keepdim=True)\n",
    "\n",
    "        outputs.append(linear_y1.squeeze(1)) \n",
    "        outputs.append(linear_y2.squeeze(1))\n",
    "        outputs.append(linear_y3.squeeze(1))\n",
    "\n",
    "        final_output = torch.stack(outputs, dim=1)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_rate):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.output_length = output_size\n",
    "        input_size = 8\n",
    "        self.encoder = EncoderLSTM(input_size, hidden_size) \n",
    "        self.decoder = DecoderLSTM(input_size, hidden_size, dropout_rate)\n",
    "        \n",
    "    def forward(self, inputs, outputs=None):\n",
    "\n",
    "        # Encode the input sequence\n",
    "        hidden = self.encoder(inputs)  # Get encoded hidden state from the encoder\n",
    "\n",
    "        # Initialize decoder input (usually last input value or a special token)\n",
    "        decoder_input = inputs[:, -1:, :] \n",
    "        # Decode the sequence\n",
    "        output = self.decoder(decoder_input, hidden, outputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "Bi_Directional_LSTM_model = Seq2Seq(hidden_size = hidden_size, \\\n",
    "                        output_size = 3, dropout_rate = 0).to(device)\n",
    "Bi_Directional_LSTM_model.load_state_dict(torch.load('./final_models/ED_LSTM.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Bidirectional Encoder-Decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoderLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(BiEncoderLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_directions = 2  # Since it's bidirectional\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        out, (hn, cn) = self.lstm(inputs)\n",
    "        hn_dec = hn[0] + hn[1]\n",
    "        cn_dec = cn[0] + cn[1]\n",
    "\n",
    "        hn_dec = hn_dec.unsqueeze(0)\n",
    "        cn_dec = cn_dec.unsqueeze(0)\n",
    "\n",
    "        return hn_dec, cn_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Implementing Prof Idea\n",
    "        self.linear1 = nn.Linear(hidden_size, 1)\n",
    "        self.linearsub1 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.linearsub2 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, hidden,):\n",
    "        outputs = []\n",
    "        decoder_input = x\n",
    "        \n",
    "        # First LSTM layer\n",
    "        decoder_input = decoder_input.to(device)\n",
    "        y1, hidden1 = self.lstm(decoder_input, hidden)\n",
    "        linear_y1 = self.linear1(y1)\n",
    "        linear_y1 = linear_y1.mean(dim=1, keepdim=True)\n",
    "        linear_suby1 = self.linearsub1(y1)\n",
    "\n",
    "        # Second LSTM layer\n",
    "        y2, hidden2 = self.lstm(linear_suby1, hidden)\n",
    "        linear_y2 = self.linear2(y2)\n",
    "        linear_suby2 = self.linearsub2(y2)\n",
    "        linear_y2 = linear_y2.mean(dim=1, keepdim=True)\n",
    "\n",
    "        y3, hidden3 = self.lstm(linear_suby2, hidden)\n",
    "        linear_y3 = self.linear3(y3)\n",
    "        linear_y3 = linear_y3.mean(dim=1, keepdim=True)\n",
    "\n",
    "        outputs.append(linear_y1.squeeze(1))  # shape: [17, 1]\n",
    "        outputs.append(linear_y2.squeeze(1))\n",
    "        outputs.append(linear_y3.squeeze(1))\n",
    "\n",
    "        final_output = torch.stack(outputs, dim=1)  # [17, 3, 1]\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, input_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.output_length = output_size\n",
    "        self.encoder = BiEncoderLSTM(input_size, hidden_size) \n",
    "        self.decoder = DecoderLSTM(input_size, hidden_size)\n",
    "        \n",
    "    def forward(self, inputs, outputs=None):\n",
    "\n",
    "        # Encode the input sequence\n",
    "        inputs = inputs.to(device)\n",
    "        hidden = self.encoder(inputs)  # Get encoded hidden state from the encoder\n",
    "\n",
    "        # Initialize decoder input (usually last input value or a special token)\n",
    "        decoder_input = inputs\n",
    "        # Decode the sequence\n",
    "        output = self.decoder(decoder_input, hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 8\n",
    "hidden_size = 128\n",
    "output_size = 3\n",
    "\n",
    "# Initialize Seq2Seq Model\n",
    "Bi_ED_LSTM_model = Seq2Seq(hidden_size = hidden_size, output_size = output_size, input_size=input_size).to(device)\n",
    "Bi_ED_LSTM_model.load_state_dict(torch.load('./final_models/Bi-ED-LSTM.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_heads, num_layers, hidden_dim, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(input_size, hidden_dim)         # input_size = 3\n",
    "        self.decoder_embedding = nn.Linear(1, hidden_dim)        \n",
    "        self.encoder_positional_encoding = nn.Parameter(torch.rand(1, 100, hidden_dim)) \n",
    "        self.decoder_positional_encoding = nn.Parameter(torch.rand(1, 100, hidden_dim))  # max_seq_len=100\n",
    "\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim, \n",
    "            nhead=num_heads, \n",
    "            num_encoder_layers=num_layers, \n",
    "            num_decoder_layers=num_layers, \n",
    "            dim_feedforward=hidden_dim * 2, \n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, src, tgt=None):\n",
    "        src = self.embedding(src)\n",
    "        src += self.encoder_positional_encoding[:, :src.size(1), :]\n",
    "\n",
    "        \n",
    "        if tgt is not None:\n",
    "            tgt_input = self.decoder_embedding(tgt)\n",
    "            tgt_input += self.decoder_positional_encoding[:, :tgt_input.size(1), :]\n",
    "        else:\n",
    "            print(\"target is using source\")\n",
    "            tgt_input = src\n",
    "\n",
    "        output = self.transformer(src, tgt_input)\n",
    "        output = self.fc_out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "input_size = 8\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "output_size = 1\n",
    "num_heads = 8\n",
    "\n",
    "# Initialize Seq2Seq Model\n",
    "transformer_model = TransformerModel(input_size, output_size, num_heads, num_layers, hidden_dim = hidden_size).to(device)\n",
    "transformer_model.load_state_dict(torch.load('./final_models/transformer.pth'))\n",
    "seed_value = random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Ensemble (State of the art) : Random Forest + XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We then want to load in our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_weather_taxi_df = \"merged_file_with_mean.csv\"\n",
    "taxi_df = pd.read_csv(merged_weather_taxi_df, delimiter = \",\")\n",
    "\n",
    "#Adjusting for weather parameters\n",
    "taxi_df = taxi_df.drop(columns = \"stationId\")\n",
    "\n",
    "#Adjusting for taxi_vailability parameters\n",
    "taxi_df_coordinates = taxi_df[\"Coordinates[]\"]\n",
    "taxt_df_datetime = taxi_df[\"DateTime\"]\n",
    "taxi_df = taxi_df.drop(columns = \"Coordinates[]\")\n",
    "taxi_df = taxi_df.drop(columns = \"Taxi Available in Selected Box Area\")\n",
    "taxi_df[\"DateTime\"] = pd.to_datetime(taxi_df[\"DateTime\"])\n",
    "\n",
    "taxi_df[\"IsWeekend\"] = (taxi_df[\"DateTime\"].dt.weekday >= 5).astype(int)\n",
    "taxi_df[\"Hour\"] = taxi_df[\"DateTime\"].dt.hour + 1  # Convert 0-23 to 1-24\n",
    "taxi_df = taxi_df.drop(columns = \"DateTime\")\n",
    "\n",
    "# taxi_df=taxi_df[:5120]\n",
    "numeric_columns = taxi_df.select_dtypes(include=['int64', 'int32','float64','object']).columns\n",
    "taxi_df[numeric_columns] = taxi_df[numeric_columns].astype('float32')\n",
    "numeric_columns = taxi_df.select_dtypes(include=['int64', 'int32','float64','object']).columns\n",
    "\n",
    "# Convert selected columns to float32\n",
    "taxi_df[numeric_columns] = taxi_df[numeric_columns].astype('float32')\n",
    "\n",
    "# #---------------Normalise-----------------------\n",
    "# Drop 'DateTime' as it's no longer needed\n",
    "# Normalize the 'Hour' and 'IsWeekend' columns (if needed)\n",
    "\n",
    "data_min = taxi_df.min(axis=0)\n",
    "data_max = taxi_df.max(axis=0)\n",
    "taxi_df_normalized = (taxi_df - data_min) / (data_max - data_min)\n",
    "\n",
    "taxi_df_output_normalized  = taxi_df_normalized[\"Average Taxi Availability\"]\n",
    "taxi_df_output_training_normalized = taxi_df_normalized[\"Average Taxi Availability\"]\n",
    "\n",
    "taxi_df_normalized.to_csv(\"checker.csv\", index=False)  # Set index=False to exclude row numbers\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "input_data = taxi_df_normalized.values  # Shape: (5120, num_features)\n",
    "output_data = taxi_df_output_normalized.values  # Shape: (5120,)\n",
    "output_training_data = taxi_df_output_training_normalized.values\n",
    "\n",
    "seq_length = 24\n",
    "pred_horizon = 3  # Number of future time steps to predict\n",
    "\n",
    "def create_sequences(data, labels, seq_length, pred_horizon):\n",
    "    xs, ys = [], []\n",
    "    for i in range(0, len(data), seq_length):  # Start from 0 and increment by seq_length\n",
    "        if i + seq_length + pred_horizon <= len(data):  # Ensure enough data for prediction horizon\n",
    "            xs.append(data[i:i + seq_length])  # Input sequence (continuous)\n",
    "            ys.append(labels[i + seq_length : i + seq_length + pred_horizon])  # Next 3 values\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "X, y = create_sequences(input_data, output_data, seq_length,pred_horizon)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y[:, None], dtype=torch.float32)\n",
    "y = y.permute(0, 2, 1)  # Shape: (samples, pred_horizon, 1)\n",
    "\n",
    "# Split sizes\n",
    "total_samples = len(X)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = int(0.1 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "# Split the data\n",
    "trainX, valX, testX = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]\n",
    "trainY, valY, testY = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(trainX, trainY)\n",
    "val_dataset = TensorDataset(valX, valY)\n",
    "test_dataset = TensorDataset(testX, testY)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 17\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display MAE and Graphs from all 6 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 8, got 9",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     21\u001b[39m     inputs, cell_state, hidden_state = inputs.to(device), cell_state, hidden_state\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     output, cell_state, hidden_state = \u001b[43mLSTM_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     output = output.unsqueeze(-\u001b[32m1\u001b[39m)\n\u001b[32m     25\u001b[39m     output, targets = output.to(device), targets.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\littl\\OneDrive\\Documents\\SUTD\\Term 8\\50.055 Special Topic Machine Learning Operations\\Lecture\\DL_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\littl\\OneDrive\\Documents\\SUTD\\Term 8\\50.055 Special Topic Machine Learning Operations\\Lecture\\DL_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mLSTM_pt.forward\u001b[39m\u001b[34m(self, x, h0, c0)\u001b[39m\n\u001b[32m     21\u001b[39m     c0 = torch.randn(\u001b[38;5;28mself\u001b[39m.layer_dim, x.size(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.hidden_dim).to(x.device)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# LSTM forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m out, (hn, cn) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Apply LayerNorm to the output of the LSTM\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# out = self.layer_norm(out)\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Pass only the last timestep's output to the FC layer\u001b[39;00m\n\u001b[32m     30\u001b[39m out = \u001b[38;5;28mself\u001b[39m.fc(out[:, -\u001b[32m1\u001b[39m, :])  \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\littl\\OneDrive\\Documents\\SUTD\\Term 8\\50.055 Special Topic Machine Learning Operations\\Lecture\\DL_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\littl\\OneDrive\\Documents\\SUTD\\Term 8\\50.055 Special Topic Machine Learning Operations\\Lecture\\DL_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\littl\\OneDrive\\Documents\\SUTD\\Term 8\\50.055 Special Topic Machine Learning Operations\\Lecture\\DL_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1120\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1117\u001b[39m             hx = (hx[\u001b[32m0\u001b[39m].unsqueeze(\u001b[32m1\u001b[39m), hx[\u001b[32m1\u001b[39m].unsqueeze(\u001b[32m1\u001b[39m))\n\u001b[32m   1118\u001b[39m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[32m   1119\u001b[39m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\littl\\OneDrive\\Documents\\SUTD\\Term 8\\50.055 Special Topic Machine Learning Operations\\Lecture\\DL_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1002\u001b[39m, in \u001b[36mLSTM.check_forward_args\u001b[39m\u001b[34m(self, input, hidden, batch_sizes)\u001b[39m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_forward_args\u001b[39m(\n\u001b[32m    997\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    998\u001b[39m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[32m    999\u001b[39m     hidden: Tuple[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1000\u001b[39m     batch_sizes: Optional[Tensor],\n\u001b[32m   1001\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_hidden_size(\n\u001b[32m   1004\u001b[39m         hidden[\u001b[32m0\u001b[39m],\n\u001b[32m   1005\u001b[39m         \u001b[38;5;28mself\u001b[39m.get_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[32m   1006\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1007\u001b[39m     )\n\u001b[32m   1008\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_hidden_size(\n\u001b[32m   1009\u001b[39m         hidden[\u001b[32m1\u001b[39m],\n\u001b[32m   1010\u001b[39m         \u001b[38;5;28mself\u001b[39m.get_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[32m   1011\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1012\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\littl\\OneDrive\\Documents\\SUTD\\Term 8\\50.055 Special Topic Machine Learning Operations\\Lecture\\DL_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:314\u001b[39m, in \u001b[36mRNNBase.check_input\u001b[39m\u001b[34m(self, input, batch_sizes)\u001b[39m\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    312\u001b[39m     )\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_size != \u001b[38;5;28minput\u001b[39m.size(-\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    315\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.input_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.size(-\u001b[32m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    316\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: input.size(-1) must be equal to input_size. Expected 8, got 9"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "LSTM_model.eval()\n",
    "\n",
    "# Initialize variables to track loss\n",
    "loss_value = 0\n",
    "num_batches = 0\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize hidden state and cell state\n",
    "hidden_state, cell_state = None, None  \n",
    "mae_list = []\n",
    "visualise_dataset = collections.defaultdict(list)\n",
    "\n",
    "# Disable gradient computation for validation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    " \n",
    "        # Forward pass\n",
    "        inputs, cell_state, hidden_state = inputs.to(device), cell_state, hidden_state\n",
    "        output, cell_state, hidden_state = LSTM_model(inputs, cell_state, hidden_state)\n",
    "        output = output.unsqueeze(-1)\n",
    "\n",
    "        output, targets = output.to(device), targets.to(device)\n",
    "\n",
    "        # Denormalize predictions and targets (for all 3 time steps)\n",
    "        inputs_denorm = inputs * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        output_denorm = output * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        targets_denorm = targets * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        \n",
    "        visualise_dataset[batch_idx] = inputs_denorm[:,:, 5:6].cpu().numpy()\n",
    "        # Add targets to visualise_dataset\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], targets_denorm.cpu().numpy()), axis=1)\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], output_denorm.cpu().numpy()), axis=1)\n",
    "\n",
    "        # Compute loss on normalized data\n",
    "        loss_value += criterion(output, targets)\n",
    "        mae = torch.mean(torch.abs(output_denorm - targets_denorm))\n",
    "        mae_list.append(mae)\n",
    "\n",
    "# Compute average loss\n",
    "loss_value = loss_value / (len(test_loader) - 1)\n",
    "print(f'Average Validation Loss: {loss_value:.4f}')\n",
    "\n",
    "mae = torch.mean(torch.tensor(mae_list))\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Visualize the predictions and targets for the first batch\n",
    "for batch_idx, data in visualise_dataset.items():\n",
    "    inputs = data[0, :24]       # First 25 timesteps\n",
    "    targets = data[0, 24:27]    # 3 timesteps: ground truth\n",
    "    predictions = data[0, 27:]  # 3 timesteps: model predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Input: plotted from timestep 0 to 24\n",
    "    plt.plot(range(24), inputs[:, -1], label='Input (Last Hour)', color='blue')\n",
    "    # Targets: plotted starting from timestep 24 to 26\n",
    "    plt.plot(range(24, 27), targets[:, -1], label='Target', color='green')\n",
    "    # Predictions: plotted from timestep 27 to 29\n",
    "    plt.plot(range(24, 27), predictions[:, -1], label='Predicted', color='red')\n",
    "    plt.title(f'Batch {batch_idx} Predictions vs Targets')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "Bi_LSTM_model.eval()\n",
    "\n",
    "# Initialize variables to track loss\n",
    "loss_value = 0\n",
    "num_batches = 0\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize hidden state and cell state\n",
    "hidden_state, cell_state = None, None  \n",
    "mae_list = []\n",
    "visualise_dataset = collections.defaultdict(list)\n",
    "\n",
    "# Disable gradient computation for validation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "        # Forward pass\n",
    "        inputs = inputs.to(device)\n",
    "        output, cell_state, hidden_state = Bi_LSTM_model(inputs, cell_state, hidden_state)\n",
    "        output = output.unsqueeze(-1).permute(0, 2, 1)\n",
    "\n",
    "        output = output.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Denormalize predictions and targets (for all 3 time steps)\n",
    "        inputs_denorm = inputs * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        output_denorm = output * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        targets_denorm = targets * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "\n",
    "        flat_output = output_denorm.view(-1).tolist()\n",
    "        result = [[[v] for v in inner[0]] for inner in output_denorm.tolist()]\n",
    "        \n",
    "        visualise_dataset[batch_idx] = inputs_denorm[:,:, 5:6].cpu().numpy()\n",
    "        # Add targets to visualise_dataset\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], targets_denorm.cpu().numpy()), axis=1)\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], result), axis=1)\n",
    "        \n",
    "        # Compute loss on normalized data\n",
    "        loss_value += criterion(output, targets)\n",
    "        mae = torch.mean(torch.abs(torch.tensor(result).to(device) - targets_denorm))\n",
    "        mae_list.append(mae)\n",
    "\n",
    "# Compute average loss\n",
    "loss_value = loss_value / (len(test_loader) - 1)\n",
    "print(f'Average Validation Loss: {loss_value:.4f}')\n",
    "\n",
    "mae = torch.mean(torch.tensor(mae_list))\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Visualize the predictions and targets for the first batch\n",
    "for batch_idx, data in visualise_dataset.items():\n",
    "    inputs = data[0, :24]       # First 25 timesteps\n",
    "    targets = data[0, 24:27]    # 3 timesteps: ground truth\n",
    "    predictions = data[0, 27:]  # 3 timesteps: model predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Input: plotted from timestep 0 to 24\n",
    "    plt.plot(range(24), inputs[:, -1], label='Input (Last Hour)', color='blue')\n",
    "    # Targets: plotted starting from timestep 24 to 26\n",
    "    plt.plot(range(24, 27), targets[:, -1], label='Target', color='green')\n",
    "    # Predictions: plotted from timestep 27 to 29\n",
    "    plt.plot(range(24, 27), predictions[:, -1], label='Predicted', color='red')\n",
    "    plt.title(f'Batch {batch_idx} Predictions vs Targets')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Encoder-Decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "Bi_Directional_LSTM_model.eval()\n",
    "\n",
    "# Initialize variables to track loss\n",
    "loss_value = 0\n",
    "num_batches = 0\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "mae_list = []\n",
    "visualise_dataset = collections.defaultdict(list)\n",
    "\n",
    "# Disable gradient computation for validation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "        # Forward pass (ensure correct hidden states are passed)\n",
    "        inputs = inputs.to(device)  # Move inputs to GPU if available\n",
    "        hidden_state, cell_state = Bi_Directional_LSTM_model.encoder(inputs)  # Get encoder hidden states\n",
    "        decoder_input = inputs  # Use the input as the initial decoder input (you could also use a special token)\n",
    "\n",
    "        # The decoder will use these hidden states\n",
    "        output = Bi_Directional_LSTM_model.decoder(decoder_input, (hidden_state, cell_state))  # Pass hidden and cell states to the decoder\n",
    "\n",
    "        output = output.to(device)  # Move output to GPU if available\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Denormalize predictions and targets (for all 3 time steps)\n",
    "        inputs_denorm = inputs * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        output_denorm = output * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        targets_denorm = targets * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        \n",
    "        visualise_dataset[batch_idx] = inputs_denorm[:,:, 5:6].cpu().numpy()\n",
    "        # Add targets to visualise_dataset\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], targets_denorm.cpu().numpy()), axis=1)\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], output_denorm.cpu().numpy()), axis=1)\n",
    "\n",
    "        # Compute loss on normalized data\n",
    "        loss_value += criterion(output, targets)\n",
    "        mae = torch.mean(torch.abs(output_denorm - targets_denorm))\n",
    "        mae_list.append(mae)\n",
    "\n",
    "# Compute average loss\n",
    "loss_value = loss_value / (len(test_loader) - 1)\n",
    "print(f'Average Validation Loss: {loss_value:.4f}')\n",
    "\n",
    "mae = torch.mean(torch.tensor(mae_list))\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Visualize the predictions and targets for the first batch\n",
    "for batch_idx, data in visualise_dataset.items():\n",
    "    inputs = data[0, :24]       # First 25 timesteps\n",
    "    targets = data[0, 24:27]    # 3 timesteps: ground truth\n",
    "    predictions = data[0, 27:]  # 3 timesteps: model predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Input: plotted from timestep 0 to 24\n",
    "    plt.plot(range(24), inputs[:, -1], label='Input (Last Hour)', color='blue')\n",
    "    # Targets: plotted starting from timestep 24 to 26\n",
    "    plt.plot(range(24, 27), targets[:, -1], label='Target', color='green')\n",
    "    # Predictions: plotted from timestep 27 to 29\n",
    "    plt.plot(range(24, 27), predictions[:, -1], label='Predicted', color='red')\n",
    "    plt.title(f'Batch {batch_idx} Predictions vs Targets')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Bidirectional Encoder-Decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "Bi_ED_LSTM_model.eval()\n",
    "\n",
    "# Initialize variables to track loss\n",
    "loss_value = 0\n",
    "num_batches = 0\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "mae_list = []\n",
    "visualise_dataset = collections.defaultdict(list)\n",
    "\n",
    "# Disable gradient computation for validation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "        # Forward pass (ensure correct hidden states are passed)\n",
    "        hidden_state, cell_state = Bi_ED_LSTM_model.encoder(inputs)  # Get encoder hidden states\n",
    "        decoder_input = inputs  # Use the input as the initial decoder input (you could also use a special token)\n",
    "\n",
    "        # The decoder will use these hidden states\n",
    "        output = Bi_ED_LSTM_model.decoder(decoder_input, (hidden_state, cell_state))  # Pass hidden and cell states to the decoder\n",
    "\n",
    "        # Denormalize predictions and targets (for all 3 time steps)\n",
    "        output = output.to(device)\n",
    "        targets = targets.to(device)\n",
    "        inputs_denorm = inputs * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        output_denorm = output * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        targets_denorm = targets * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        \n",
    "        visualise_dataset[batch_idx] = inputs_denorm[:,:, 5:6].cpu().numpy()\n",
    "        # Add targets to visualise_dataset\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], targets_denorm.cpu().numpy()), axis=1)\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], output_denorm.cpu().numpy()), axis=1)\n",
    "\n",
    "        # Compute loss on normalized data\n",
    "        loss_value += criterion(output, targets)\n",
    "        mae = torch.mean(torch.abs(output_denorm - targets_denorm))\n",
    "        mae_list.append(mae)\n",
    "\n",
    "# Compute average loss\n",
    "loss_value = loss_value / (len(test_loader) - 1)\n",
    "print(f'Average Validation Loss: {loss_value:.4f}')\n",
    "\n",
    "mae = torch.mean(torch.tensor(mae_list))\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Visualize the predictions and targets for the first batch\n",
    "for batch_idx, data in visualise_dataset.items():\n",
    "    inputs = data[0, :24]       # First 25 timesteps\n",
    "    targets = data[0, 24:27]    # 3 timesteps: ground truth\n",
    "    predictions = data[0, 27:]  # 3 timesteps: model predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Input: plotted from timestep 0 to 24\n",
    "    plt.plot(range(24), inputs[:, -1], label='Input (Last Hour)', color='blue')\n",
    "    # Targets: plotted starting from timestep 24 to 26\n",
    "    plt.plot(range(24, 27), targets[:, -1], label='Target', color='green')\n",
    "    # Predictions: plotted from timestep 27 to 29\n",
    "    plt.plot(range(24, 27), predictions[:, -1], label='Predicted', color='red')\n",
    "    plt.title(f'Batch {batch_idx} Predictions vs Targets')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "transformer_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to track loss\n",
    "loss_value = 0\n",
    "num_batches = 0\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "mae_list = []\n",
    "visualise_dataset = collections.defaultdict(list)\n",
    "\n",
    "# Disable gradient computation for validation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "        # Move data to device\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # inputs: [B, 24, 7], targets: [B, 3, 1]\n",
    "\n",
    "        # Initialize decoder input with a fixed token, e.g., 0.0\n",
    "        batch_size = inputs.size(0)\n",
    "        tgt_input = inputs[:, -1:, 5:6]  # Feed in last input as first output\n",
    "\n",
    "        # Autoregressive prediction\n",
    "        for step in range(targets.size(1)):  # Predict 3 steps\n",
    "            output = transformer_model(inputs, tgt=tgt_input)  # output: [B, current_step+1, 1]\n",
    "            next_token = output[:, -1:, :]  # [B, 1, 1]\n",
    "            tgt_input = torch.cat([tgt_input, next_token], dim=1)  # Grow decoder input\n",
    "\n",
    "        # Skip the first token (initial start token)\n",
    "        predicted = tgt_input[:, 1:, :]  # [B, 3, 1]\n",
    "\n",
    "        # Denormalize predictions and targets\n",
    "        inputs_denorm = inputs * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        output_denorm = predicted * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        targets_denorm = targets * (data_max[\"Average Taxi Availability\"] - data_min[\"Average Taxi Availability\"]) + data_min[\"Average Taxi Availability\"]\n",
    "        \n",
    "        visualise_dataset[batch_idx] = inputs_denorm[:,:, 5:6].cpu().numpy()\n",
    "        # Add targets to visualise_dataset\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], targets_denorm.cpu().numpy()), axis=1)\n",
    "        visualise_dataset[batch_idx] = np.concatenate((visualise_dataset[batch_idx], output_denorm.cpu().numpy()), axis=1)\n",
    "\n",
    "        # Compute loss on normalized data\n",
    "        loss_value += criterion(output, targets)\n",
    "        mae = torch.mean(torch.abs(output_denorm - targets_denorm))\n",
    "        mae_list.append(mae)\n",
    "\n",
    "# Compute average loss\n",
    "loss_value = loss_value / (len(test_loader) - 1)\n",
    "print(f'Average Validation Loss: {loss_value:.4f}')\n",
    "\n",
    "mae = torch.mean(torch.tensor(mae_list))\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Visualize the predictions and targets for the first batch\n",
    "for batch_idx, data in visualise_dataset.items():\n",
    "    inputs = data[0, :24]       # First 25 timesteps\n",
    "    targets = data[0, 24:27]    # 3 timesteps: ground truth\n",
    "    predictions = data[0, 27:]  # 3 timesteps: model predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Input: plotted from timestep 0 to 24\n",
    "    plt.plot(range(24), inputs[:, -1], label='Input (Last Hour)', color='blue')\n",
    "    # Targets: plotted starting from timestep 24 to 26\n",
    "    plt.plot(range(24, 27), targets[:, -1], label='Target', color='green')\n",
    "    # Predictions: plotted from timestep 27 to 29\n",
    "    plt.plot(range(24, 27), predictions[:, -1], label='Predicted', color='red')\n",
    "    plt.title(f'Batch {batch_idx} Predictions vs Targets')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Ensemble (State of the art) : Random Forest + XGboost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
