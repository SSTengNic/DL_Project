{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxi Available throughout SG           1924\n",
      "Taxi Available in Selected Box Area      79\n",
      "IsWeekend                                 0\n",
      "Hour                                     24\n",
      "Name: 0, dtype: object\n",
      "(5120, 4)\n",
      "X[0]:  [[1.92400000e+03 0.00000000e+00 1.00000000e+00]\n",
      " [2.25900000e+03 0.00000000e+00 9.56521739e-01]\n",
      " [2.40000000e+03 0.00000000e+00 9.13043478e-01]\n",
      " [2.67700000e+03 0.00000000e+00 8.69565217e-01]\n",
      " [2.43700000e+03 0.00000000e+00 8.26086957e-01]\n",
      " [1.47900000e+03 0.00000000e+00 7.82608696e-01]\n",
      " [1.76500000e+03 0.00000000e+00 7.39130435e-01]\n",
      " [1.87700000e+03 0.00000000e+00 6.95652174e-01]\n",
      " [1.90800000e+03 0.00000000e+00 6.52173913e-01]\n",
      " [2.04600000e+03 0.00000000e+00 6.08695652e-01]\n",
      " [1.57600000e+03 0.00000000e+00 5.65217391e-01]\n",
      " [2.00000000e+03 0.00000000e+00 5.21739130e-01]\n",
      " [2.27000000e+03 0.00000000e+00 4.78260870e-01]\n",
      " [2.50000000e+03 0.00000000e+00 4.34782609e-01]\n",
      " [2.40600000e+03 0.00000000e+00 3.91304348e-01]\n",
      " [2.42800000e+03 0.00000000e+00 3.47826087e-01]\n",
      " [1.82600000e+03 0.00000000e+00 3.04347826e-01]\n",
      " [1.50000000e+03 0.00000000e+00 2.60869565e-01]\n",
      " [1.61700000e+03 0.00000000e+00 2.17391304e-01]\n",
      " [1.68800000e+03 0.00000000e+00 1.73913043e-01]\n",
      " [1.67800000e+03 0.00000000e+00 1.30434783e-01]\n",
      " [1.74100000e+03 0.00000000e+00 8.69565217e-02]\n",
      " [1.96100000e+03 0.00000000e+00 4.34782609e-02]\n",
      " [1.62600000e+03 0.00000000e+00 0.00000000e+00]]\n",
      "y[0]:  [ 77  97  88 ... 112 111 140]\n"
     ]
    }
   ],
   "source": [
    "taxi_availability_file_path = \"taxi_availability.csv\"\n",
    "\n",
    "taxi_df = pd.read_csv(taxi_availability_file_path, delimiter=\",\")\n",
    "# Save this just in case we need it in the future.\n",
    "taxi_df_coordinates = taxi_df[\"Coordinates[]\"]\n",
    "taxt_df_datetime = taxi_df[\"DateTime\"]\n",
    "taxi_df = taxi_df.drop(columns = \"Coordinates[]\")\n",
    "\n",
    "taxi_df[\"DateTime\"] = pd.to_datetime(taxi_df[\"DateTime\"])\n",
    "\n",
    "\n",
    "taxi_df[\"IsWeekend\"] = (taxi_df[\"DateTime\"].dt.weekday >= 5).astype(int)\n",
    "taxi_df[\"Hour\"] = taxi_df[\"DateTime\"].dt.hour + 1  # Convert 0-23 to 1-24\n",
    "taxi_df = taxi_df.drop(columns = \"DateTime\")\n",
    "\n",
    "#it takes 23:59:59 as midnight, same for every DateTime value.\n",
    "print(taxi_df.iloc[0])\n",
    "\n",
    "\n",
    "#---------------Normalise-----------------------\n",
    "# Drop 'DateTime' as it's no longer needed\n",
    "\n",
    "# Normalize the 'Hour' and 'IsWeekend' columns (if needed)\n",
    "taxi_df = taxi_df[:5120]\n",
    "print(taxi_df.shape)\n",
    "scaler = MinMaxScaler()\n",
    "taxi_df[[\"Hour\", \"IsWeekend\"]] = scaler.fit_transform(taxi_df[[\"Hour\", \"IsWeekend\"]])\n",
    "taxi_df = taxi_df.apply(pd.to_numeric, errors='coerce')\n",
    "taxi_df_output  = taxi_df[\"Taxi Available in Selected Box Area\"]\n",
    "taxi_df = taxi_df.drop(columns = \"Taxi Available in Selected Box Area\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "input_data = taxi_df.values  # Shape: (5120, num_features)\n",
    "output_data = taxi_df_output.values  # Shape: (5120,)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 24\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, labels, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i : i + seq_length])  # Input sequence\n",
    "        ys.append(labels[i + seq_length])   # Corresponding target\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(input_data, output_data, seq_length)\n",
    "\n",
    "print(\"X[0]: \", X[0])\n",
    "print(\"y[0]: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5096, 24, 3])\n",
      "torch.Size([5096])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainX = torch.tensor(X, dtype=torch.float32)\n",
    "trainY = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX torch.Size([990, 10, 1])\n",
      "trainY:  torch.Size([990, 1])\n"
     ]
    }
   ],
   "source": [
    "t = np.linspace(0, 100, 1000)\n",
    "data = np.sin(t)\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 10\n",
    "X, y = create_sequences(data, seq_length)\n",
    "\n",
    "trainX = torch.tensor(X[:, :, None], dtype=torch.float32)\n",
    "trainY = torch.tensor(y[:, None], dtype=torch.float32)\n",
    "print(\"trainX\",trainX.shape)\n",
    "print(\"trainY: \", trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMModel(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, layer_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:78\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     67\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     68\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused,\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:371\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    368\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_compile.py:27\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:53\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     _disable_current_modes,\n\u001b[0;32m     49\u001b[0m     is_in_torch_dispatch_mode,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback, format_traceback_short\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     56\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[0;32m     57\u001b[0m     Instruction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     transform_code_object,\n\u001b[0;32m     61\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresume_execution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     BuiltinVariable,\n\u001b[0;32m     48\u001b[0m     FunctionalCallVariable,\n\u001b[0;32m     49\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[0;32m     50\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     51\u001b[0m     PolyfilledFunctionVariable,\n\u001b[0;32m     52\u001b[0m     SkipFunctionVariable,\n\u001b[0;32m     53\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[0;32m     54\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     55\u001b[0m     UserMethodVariable,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     59\u001b[0m np: Optional[types\u001b[38;5;241m.\u001b[39mModuleType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:104\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SDPAParamsVariable\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     97\u001b[0m     FakeItemVariable,\n\u001b[0;32m     98\u001b[0m     NumpyNdarrayVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     UntypedStorageVariable,\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchCtxManagerClassVariable, TorchInGraphFunctionVariable\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_defined\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    106\u001b[0m     MutableMappingVariable,\n\u001b[0;32m    107\u001b[0m     RemovableHandleVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m     WeakRefVariable,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    114\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionContextVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWithExitFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    179\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\nicho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\variables\\torch.py:142\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Convert to dict for O(1) access times\u001b[39;00m\n\u001b[0;32m    133\u001b[0m constant_fold_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(constant_fold_functions)\n\u001b[0;32m    136\u001b[0m tracing_state_functions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    137\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    138\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    139\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    140\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39m_symbolic_trace\u001b[38;5;241m.\u001b[39mis_fx_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mis_in_onnx_export: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m--> 142\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexternal_utils\u001b[49m\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    144\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    145\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_dynamo_compiling: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    146\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mactivation\u001b[38;5;241m.\u001b[39m_is_make_fx_tracing: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m }\n\u001b[0;32m    149\u001b[0m bin_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBaseTorchVariable\u001b[39;00m(VariableTracker):\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'external_utils' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_dim=1, hidden_dim=100, layer_dim=1, output_dim=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2877\n",
      "Epoch [20/100], Loss: 0.1027\n",
      "Epoch [30/100], Loss: 0.0419\n",
      "Epoch [40/100], Loss: 0.0167\n",
      "Epoch [50/100], Loss: 0.0032\n",
      "Epoch [60/100], Loss: 0.0007\n",
      "Epoch [70/100], Loss: 0.0004\n",
      "Epoch [80/100], Loss: 0.0004\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [100/100], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "h0, c0 = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "    loss = criterion(outputs, trainY)\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    h0 = h0.detach()\n",
    "    c0 = c0.detach()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8432],\n",
      "        [ 0.8907],\n",
      "        [ 0.9297],\n",
      "        [ 0.9600],\n",
      "        [ 0.9815],\n",
      "        [ 0.9938],\n",
      "        [ 0.9969],\n",
      "        [ 0.9908],\n",
      "        [ 0.9752],\n",
      "        [ 0.9502],\n",
      "        [ 0.9158],\n",
      "        [ 0.8722],\n",
      "        [ 0.8195],\n",
      "        [ 0.7580],\n",
      "        [ 0.6882],\n",
      "        [ 0.6107],\n",
      "        [ 0.5262],\n",
      "        [ 0.4358],\n",
      "        [ 0.3404],\n",
      "        [ 0.2412],\n",
      "        [ 0.1396],\n",
      "        [ 0.0369],\n",
      "        [-0.0655],\n",
      "        [-0.1666],\n",
      "        [-0.2649],\n",
      "        [-0.3597],\n",
      "        [-0.4499],\n",
      "        [-0.5348],\n",
      "        [-0.6137],\n",
      "        [-0.6863],\n",
      "        [-0.7518],\n",
      "        [-0.8100],\n",
      "        [-0.8605],\n",
      "        [-0.9029],\n",
      "        [-0.9370],\n",
      "        [-0.9624],\n",
      "        [-0.9789],\n",
      "        [-0.9864],\n",
      "        [-0.9846],\n",
      "        [-0.9735],\n",
      "        [-0.9531],\n",
      "        [-0.9233],\n",
      "        [-0.8843],\n",
      "        [-0.8361],\n",
      "        [-0.7791],\n",
      "        [-0.7137],\n",
      "        [-0.6402],\n",
      "        [-0.5594],\n",
      "        [-0.4720],\n",
      "        [-0.3789],\n",
      "        [-0.2813],\n",
      "        [-0.1804],\n",
      "        [-0.0775],\n",
      "        [ 0.0262],\n",
      "        [ 0.1292],\n",
      "        [ 0.2303],\n",
      "        [ 0.3283],\n",
      "        [ 0.4221],\n",
      "        [ 0.5108],\n",
      "        [ 0.5937],\n",
      "        [ 0.6700],\n",
      "        [ 0.7393],\n",
      "        [ 0.8010],\n",
      "        [ 0.8549],\n",
      "        [ 0.9004],\n",
      "        [ 0.9375],\n",
      "        [ 0.9658],\n",
      "        [ 0.9851],\n",
      "        [ 0.9954],\n",
      "        [ 0.9963],\n",
      "        [ 0.9880],\n",
      "        [ 0.9702],\n",
      "        [ 0.9431],\n",
      "        [ 0.9066],\n",
      "        [ 0.8608],\n",
      "        [ 0.8061],\n",
      "        [ 0.7426],\n",
      "        [ 0.6710],\n",
      "        [ 0.5918],\n",
      "        [ 0.5058],\n",
      "        [ 0.4141],\n",
      "        [ 0.3177],\n",
      "        [ 0.2179],\n",
      "        [ 0.1160],\n",
      "        [ 0.0132],\n",
      "        [-0.0891],\n",
      "        [-0.1896],\n",
      "        [-0.2872],\n",
      "        [-0.3809],\n",
      "        [-0.4700],\n",
      "        [-0.5536],\n",
      "        [-0.6311],\n",
      "        [-0.7020],\n",
      "        [-0.7659],\n",
      "        [-0.8224],\n",
      "        [-0.8711],\n",
      "        [-0.9116],\n",
      "        [-0.9436],\n",
      "        [-0.9670],\n",
      "        [-0.9814],\n",
      "        [-0.9868],\n",
      "        [-0.9829],\n",
      "        [-0.9696],\n",
      "        [-0.9470],\n",
      "        [-0.9151],\n",
      "        [-0.8740],\n",
      "        [-0.8237],\n",
      "        [-0.7647],\n",
      "        [-0.6974],\n",
      "        [-0.6221],\n",
      "        [-0.5397],\n",
      "        [-0.4509],\n",
      "        [-0.3567],\n",
      "        [-0.2583],\n",
      "        [-0.1568],\n",
      "        [-0.0535],\n",
      "        [ 0.0501],\n",
      "        [ 0.1528],\n",
      "        [ 0.2532],\n",
      "        [ 0.3503],\n",
      "        [ 0.4431],\n",
      "        [ 0.5305],\n",
      "        [ 0.6119],\n",
      "        [ 0.6867],\n",
      "        [ 0.7543],\n",
      "        [ 0.8142],\n",
      "        [ 0.8661],\n",
      "        [ 0.9098],\n",
      "        [ 0.9448],\n",
      "        [ 0.9711],\n",
      "        [ 0.9883],\n",
      "        [ 0.9964],\n",
      "        [ 0.9952],\n",
      "        [ 0.9847],\n",
      "        [ 0.9648],\n",
      "        [ 0.9355],\n",
      "        [ 0.8968],\n",
      "        [ 0.8490],\n",
      "        [ 0.7922],\n",
      "        [ 0.7268],\n",
      "        [ 0.6533],\n",
      "        [ 0.5725],\n",
      "        [ 0.4851],\n",
      "        [ 0.3922],\n",
      "        [ 0.2949],\n",
      "        [ 0.1945],\n",
      "        [ 0.0922],\n",
      "        [-0.0105],\n",
      "        [-0.1125],\n",
      "        [-0.2124],\n",
      "        [-0.3092],\n",
      "        [-0.4020],\n",
      "        [-0.4898],\n",
      "        [-0.5720],\n",
      "        [-0.6481],\n",
      "        [-0.7174],\n",
      "        [-0.7797],\n",
      "        [-0.8343],\n",
      "        [-0.8811],\n",
      "        [-0.9197],\n",
      "        [-0.9498],\n",
      "        [-0.9711],\n",
      "        [-0.9835],\n",
      "        [-0.9867],\n",
      "        [-0.9807],\n",
      "        [-0.9653],\n",
      "        [-0.9405],\n",
      "        [-0.9064],\n",
      "        [-0.8631],\n",
      "        [-0.8109],\n",
      "        [-0.7499],\n",
      "        [-0.6807],\n",
      "        [-0.6037],\n",
      "        [-0.5197],\n",
      "        [-0.4296],\n",
      "        [-0.3343],\n",
      "        [-0.2351],\n",
      "        [-0.1330],\n",
      "        [-0.0296],\n",
      "        [ 0.0739],\n",
      "        [ 0.1762],\n",
      "        [ 0.2760],\n",
      "        [ 0.3722],\n",
      "        [ 0.4637],\n",
      "        [ 0.5499],\n",
      "        [ 0.6298],\n",
      "        [ 0.7029],\n",
      "        [ 0.7688],\n",
      "        [ 0.8269],\n",
      "        [ 0.8770],\n",
      "        [ 0.9186],\n",
      "        [ 0.9517],\n",
      "        [ 0.9758],\n",
      "        [ 0.9910],\n",
      "        [ 0.9970],\n",
      "        [ 0.9937],\n",
      "        [ 0.9810],\n",
      "        [ 0.9589],\n",
      "        [ 0.9274],\n",
      "        [ 0.8866],\n",
      "        [ 0.8366],\n",
      "        [ 0.7778],\n",
      "        [ 0.7105],\n",
      "        [ 0.6353],\n",
      "        [ 0.5529],\n",
      "        [ 0.4641],\n",
      "        [ 0.3701],\n",
      "        [ 0.2720],\n",
      "        [ 0.1710],\n",
      "        [ 0.0685],\n",
      "        [-0.0342],\n",
      "        [-0.1358],\n",
      "        [-0.2351],\n",
      "        [-0.3310],\n",
      "        [-0.4227],\n",
      "        [-0.5093],\n",
      "        [-0.5902],\n",
      "        [-0.6647],\n",
      "        [-0.7325],\n",
      "        [-0.7930],\n",
      "        [-0.8459],\n",
      "        [-0.8908],\n",
      "        [-0.9274],\n",
      "        [-0.9555],\n",
      "        [-0.9748],\n",
      "        [-0.9851],\n",
      "        [-0.9861],\n",
      "        [-0.9779],\n",
      "        [-0.9604],\n",
      "        [-0.9335],\n",
      "        [-0.8972],\n",
      "        [-0.8519],\n",
      "        [-0.7976],\n",
      "        [-0.7346],\n",
      "        [-0.6636],\n",
      "        [-0.5849],\n",
      "        [-0.4994],\n",
      "        [-0.4080],\n",
      "        [-0.3117],\n",
      "        [-0.2117],\n",
      "        [-0.1092],\n",
      "        [-0.0056],\n",
      "        [ 0.0977],\n",
      "        [ 0.1995],\n",
      "        [ 0.2986],\n",
      "        [ 0.3938],\n",
      "        [ 0.4841],\n",
      "        [ 0.5689],\n",
      "        [ 0.6473],\n",
      "        [ 0.7188],\n",
      "        [ 0.7829],\n",
      "        [ 0.8392],\n",
      "        [ 0.8873],\n",
      "        [ 0.9270],\n",
      "        [ 0.9580],\n",
      "        [ 0.9802],\n",
      "        [ 0.9932],\n",
      "        [ 0.9970],\n",
      "        [ 0.9916],\n",
      "        [ 0.9767],\n",
      "        [ 0.9524],\n",
      "        [ 0.9188],\n",
      "        [ 0.8758],\n",
      "        [ 0.8238],\n",
      "        [ 0.7630],\n",
      "        [ 0.6938],\n",
      "        [ 0.6169],\n",
      "        [ 0.5329],\n",
      "        [ 0.4428],\n",
      "        [ 0.3478],\n",
      "        [ 0.2489],\n",
      "        [ 0.1474],\n",
      "        [ 0.0448],\n",
      "        [-0.0578],\n",
      "        [-0.1590],\n",
      "        [-0.2576],\n",
      "        [-0.3526],\n",
      "        [-0.4432],\n",
      "        [-0.5285],\n",
      "        [-0.6080],\n",
      "        [-0.6810],\n",
      "        [-0.7471],\n",
      "        [-0.8059],\n",
      "        [-0.8570],\n",
      "        [-0.9000],\n",
      "        [-0.9347],\n",
      "        [-0.9608],\n",
      "        [-0.9780],\n",
      "        [-0.9861],\n",
      "        [-0.9851],\n",
      "        [-0.9747],\n",
      "        [-0.9550],\n",
      "        [-0.9259],\n",
      "        [-0.8876],\n",
      "        [-0.8401],\n",
      "        [-0.7838],\n",
      "        [-0.7189],\n",
      "        [-0.6460],\n",
      "        [-0.5657],\n",
      "        [-0.4788],\n",
      "        [-0.3862],\n",
      "        [-0.2889],\n",
      "        [-0.1882],\n",
      "        [-0.0853],\n",
      "        [ 0.0183],\n",
      "        [ 0.1214],\n",
      "        [ 0.2227],\n",
      "        [ 0.3209],\n",
      "        [ 0.4151],\n",
      "        [ 0.5043],\n",
      "        [ 0.5876],\n",
      "        [ 0.6645],\n",
      "        [ 0.7343],\n",
      "        [ 0.7966],\n",
      "        [ 0.8511],\n",
      "        [ 0.8973],\n",
      "        [ 0.9350],\n",
      "        [ 0.9639],\n",
      "        [ 0.9840],\n",
      "        [ 0.9949],\n",
      "        [ 0.9966],\n",
      "        [ 0.9890],\n",
      "        [ 0.9719],\n",
      "        [ 0.9455],\n",
      "        [ 0.9097],\n",
      "        [ 0.8646],\n",
      "        [ 0.8105],\n",
      "        [ 0.7477],\n",
      "        [ 0.6767],\n",
      "        [ 0.5981],\n",
      "        [ 0.5126],\n",
      "        [ 0.4213],\n",
      "        [ 0.3252],\n",
      "        [ 0.2256],\n",
      "        [ 0.1238],\n",
      "        [ 0.0210],\n",
      "        [-0.0813],\n",
      "        [-0.1820],\n",
      "        [-0.2799],\n",
      "        [-0.3740],\n",
      "        [-0.4634],\n",
      "        [-0.5474],\n",
      "        [-0.6254],\n",
      "        [-0.6969],\n",
      "        [-0.7613],\n",
      "        [-0.8184],\n",
      "        [-0.8676],\n",
      "        [-0.9088],\n",
      "        [-0.9415],\n",
      "        [-0.9655],\n",
      "        [-0.9807],\n",
      "        [-0.9867],\n",
      "        [-0.9835],\n",
      "        [-0.9710],\n",
      "        [-0.9491],\n",
      "        [-0.9179],\n",
      "        [-0.8774],\n",
      "        [-0.8279],\n",
      "        [-0.7695],\n",
      "        [-0.7028],\n",
      "        [-0.6281],\n",
      "        [-0.5462],\n",
      "        [-0.4579],\n",
      "        [-0.3641],\n",
      "        [-0.2659],\n",
      "        [-0.1646],\n",
      "        [-0.0614],\n",
      "        [ 0.0422],\n",
      "        [ 0.1450],\n",
      "        [ 0.2457],\n",
      "        [ 0.3431],\n",
      "        [ 0.4362],\n",
      "        [ 0.5240],\n",
      "        [ 0.6059],\n",
      "        [ 0.6812],\n",
      "        [ 0.7494],\n",
      "        [ 0.8099],\n",
      "        [ 0.8625],\n",
      "        [ 0.9067],\n",
      "        [ 0.9425],\n",
      "        [ 0.9694],\n",
      "        [ 0.9873],\n",
      "        [ 0.9961],\n",
      "        [ 0.9957],\n",
      "        [ 0.9859],\n",
      "        [ 0.9667],\n",
      "        [ 0.9380],\n",
      "        [ 0.9001],\n",
      "        [ 0.8529],\n",
      "        [ 0.7968],\n",
      "        [ 0.7320],\n",
      "        [ 0.6592],\n",
      "        [ 0.5789],\n",
      "        [ 0.4920],\n",
      "        [ 0.3995],\n",
      "        [ 0.3025],\n",
      "        [ 0.2022],\n",
      "        [ 0.1001],\n",
      "        [-0.0027],\n",
      "        [-0.1048],\n",
      "        [-0.2049],\n",
      "        [-0.3020],\n",
      "        [-0.3951],\n",
      "        [-0.4833],\n",
      "        [-0.5660],\n",
      "        [-0.6425],\n",
      "        [-0.7124],\n",
      "        [-0.7752],\n",
      "        [-0.8305],\n",
      "        [-0.8779],\n",
      "        [-0.9171],\n",
      "        [-0.9478],\n",
      "        [-0.9698],\n",
      "        [-0.9829],\n",
      "        [-0.9868],\n",
      "        [-0.9814],\n",
      "        [-0.9668],\n",
      "        [-0.9427],\n",
      "        [-0.9093],\n",
      "        [-0.8668],\n",
      "        [-0.8152],\n",
      "        [-0.7548],\n",
      "        [-0.6862],\n",
      "        [-0.6098],\n",
      "        [-0.5264],\n",
      "        [-0.4367],\n",
      "        [-0.3417],\n",
      "        [-0.2427],\n",
      "        [-0.1409],\n",
      "        [-0.0375],\n",
      "        [ 0.0661],\n",
      "        [ 0.1685],\n",
      "        [ 0.2685],\n",
      "        [ 0.3650],\n",
      "        [ 0.4570],\n",
      "        [ 0.5435],\n",
      "        [ 0.6239],\n",
      "        [ 0.6976],\n",
      "        [ 0.7640],\n",
      "        [ 0.8228],\n",
      "        [ 0.8735],\n",
      "        [ 0.9158],\n",
      "        [ 0.9495],\n",
      "        [ 0.9743],\n",
      "        [ 0.9902],\n",
      "        [ 0.9968],\n",
      "        [ 0.9942],\n",
      "        [ 0.9823],\n",
      "        [ 0.9609],\n",
      "        [ 0.9301],\n",
      "        [ 0.8900],\n",
      "        [ 0.8407],\n",
      "        [ 0.7826],\n",
      "        [ 0.7159],\n",
      "        [ 0.6413],\n",
      "        [ 0.5594],\n",
      "        [ 0.4711],\n",
      "        [ 0.3774],\n",
      "        [ 0.2796],\n",
      "        [ 0.1787],\n",
      "        [ 0.0763],\n",
      "        [-0.0264],\n",
      "        [-0.1281],\n",
      "        [-0.2276],\n",
      "        [-0.3239],\n",
      "        [-0.4159],\n",
      "        [-0.5029],\n",
      "        [-0.5842],\n",
      "        [-0.6593],\n",
      "        [-0.7275],\n",
      "        [-0.7886],\n",
      "        [-0.8421],\n",
      "        [-0.8877],\n",
      "        [-0.9250],\n",
      "        [-0.9537],\n",
      "        [-0.9736],\n",
      "        [-0.9846],\n",
      "        [-0.9864],\n",
      "        [-0.9789],\n",
      "        [-0.9620],\n",
      "        [-0.9358],\n",
      "        [-0.9003],\n",
      "        [-0.8556],\n",
      "        [-0.8020],\n",
      "        [-0.7397],\n",
      "        [-0.6692],\n",
      "        [-0.5911],\n",
      "        [-0.5062],\n",
      "        [-0.4152],\n",
      "        [-0.3192],\n",
      "        [-0.2194],\n",
      "        [-0.1171],\n",
      "        [-0.0135],\n",
      "        [ 0.0899],\n",
      "        [ 0.1919],\n",
      "        [ 0.2912],\n",
      "        [ 0.3867],\n",
      "        [ 0.4775],\n",
      "        [ 0.5627],\n",
      "        [ 0.6416],\n",
      "        [ 0.7136],\n",
      "        [ 0.7783],\n",
      "        [ 0.8352],\n",
      "        [ 0.8840],\n",
      "        [ 0.9243],\n",
      "        [ 0.9560],\n",
      "        [ 0.9788],\n",
      "        [ 0.9925],\n",
      "        [ 0.9971],\n",
      "        [ 0.9923],\n",
      "        [ 0.9782],\n",
      "        [ 0.9546],\n",
      "        [ 0.9217],\n",
      "        [ 0.8794],\n",
      "        [ 0.8281],\n",
      "        [ 0.7679],\n",
      "        [ 0.6993],\n",
      "        [ 0.6230],\n",
      "        [ 0.5395],\n",
      "        [ 0.4499],\n",
      "        [ 0.3551],\n",
      "        [ 0.2565],\n",
      "        [ 0.1552],\n",
      "        [ 0.0526],\n",
      "        [-0.0500],\n",
      "        [-0.1513],\n",
      "        [-0.2502],\n",
      "        [-0.3455],\n",
      "        [-0.4365],\n",
      "        [-0.5222],\n",
      "        [-0.6021],\n",
      "        [-0.6757],\n",
      "        [-0.7423],\n",
      "        [-0.8017],\n",
      "        [-0.8534],\n",
      "        [-0.8970],\n",
      "        [-0.9324],\n",
      "        [-0.9591],\n",
      "        [-0.9770],\n",
      "        [-0.9858],\n",
      "        [-0.9855],\n",
      "        [-0.9758],\n",
      "        [-0.9568],\n",
      "        [-0.9285],\n",
      "        [-0.8908],\n",
      "        [-0.8440],\n",
      "        [-0.7884],\n",
      "        [-0.7241],\n",
      "        [-0.6519],\n",
      "        [-0.5721],\n",
      "        [-0.4856],\n",
      "        [-0.3934],\n",
      "        [-0.2964],\n",
      "        [-0.1959],\n",
      "        [-0.0932],\n",
      "        [ 0.0104],\n",
      "        [ 0.1136],\n",
      "        [ 0.2151],\n",
      "        [ 0.3136],\n",
      "        [ 0.4081],\n",
      "        [ 0.4977],\n",
      "        [ 0.5815],\n",
      "        [ 0.6589],\n",
      "        [ 0.7292],\n",
      "        [ 0.7922],\n",
      "        [ 0.8472],\n",
      "        [ 0.8941],\n",
      "        [ 0.9324],\n",
      "        [ 0.9621],\n",
      "        [ 0.9828],\n",
      "        [ 0.9944],\n",
      "        [ 0.9968],\n",
      "        [ 0.9899],\n",
      "        [ 0.9736],\n",
      "        [ 0.9478],\n",
      "        [ 0.9127],\n",
      "        [ 0.8684],\n",
      "        [ 0.8150],\n",
      "        [ 0.7528],\n",
      "        [ 0.6824],\n",
      "        [ 0.6043],\n",
      "        [ 0.5193],\n",
      "        [ 0.4284],\n",
      "        [ 0.3327],\n",
      "        [ 0.2333],\n",
      "        [ 0.1316],\n",
      "        [ 0.0288],\n",
      "        [-0.0736],\n",
      "        [-0.1744],\n",
      "        [-0.2726],\n",
      "        [-0.3670],\n",
      "        [-0.4568],\n",
      "        [-0.5412],\n",
      "        [-0.6197],\n",
      "        [-0.6917],\n",
      "        [-0.7567],\n",
      "        [-0.8143],\n",
      "        [-0.8642],\n",
      "        [-0.9059],\n",
      "        [-0.9393],\n",
      "        [-0.9640],\n",
      "        [-0.9798],\n",
      "        [-0.9866],\n",
      "        [-0.9841],\n",
      "        [-0.9723],\n",
      "        [-0.9511],\n",
      "        [-0.9206],\n",
      "        [-0.8808],\n",
      "        [-0.8320],\n",
      "        [-0.7743],\n",
      "        [-0.7081],\n",
      "        [-0.6341],\n",
      "        [-0.5527],\n",
      "        [-0.4648],\n",
      "        [-0.3714],\n",
      "        [-0.2735],\n",
      "        [-0.1724],\n",
      "        [-0.0693],\n",
      "        [ 0.0344],\n",
      "        [ 0.1373],\n",
      "        [ 0.2381],\n",
      "        [ 0.3358],\n",
      "        [ 0.4293],\n",
      "        [ 0.5176],\n",
      "        [ 0.5999],\n",
      "        [ 0.6757],\n",
      "        [ 0.7444],\n",
      "        [ 0.8056],\n",
      "        [ 0.8588],\n",
      "        [ 0.9037],\n",
      "        [ 0.9400],\n",
      "        [ 0.9676],\n",
      "        [ 0.9863],\n",
      "        [ 0.9958],\n",
      "        [ 0.9960],\n",
      "        [ 0.9869],\n",
      "        [ 0.9684],\n",
      "        [ 0.9406],\n",
      "        [ 0.9033],\n",
      "        [ 0.8568],\n",
      "        [ 0.8014],\n",
      "        [ 0.7373],\n",
      "        [ 0.6650],\n",
      "        [ 0.5852],\n",
      "        [ 0.4988],\n",
      "        [ 0.4067],\n",
      "        [ 0.3100],\n",
      "        [ 0.2099],\n",
      "        [ 0.1079],\n",
      "        [ 0.0051],\n",
      "        [-0.0971],\n",
      "        [-0.1974],\n",
      "        [-0.2947],\n",
      "        [-0.3881],\n",
      "        [-0.4768],\n",
      "        [-0.5599],\n",
      "        [-0.6369],\n",
      "        [-0.7073],\n",
      "        [-0.7707],\n",
      "        [-0.8265],\n",
      "        [-0.8745],\n",
      "        [-0.9144],\n",
      "        [-0.9458],\n",
      "        [-0.9685],\n",
      "        [-0.9822],\n",
      "        [-0.9868],\n",
      "        [-0.9822],\n",
      "        [-0.9682],\n",
      "        [-0.9449],\n",
      "        [-0.9122],\n",
      "        [-0.8703],\n",
      "        [-0.8194],\n",
      "        [-0.7597],\n",
      "        [-0.6917],\n",
      "        [-0.6159],\n",
      "        [-0.5329],\n",
      "        [-0.4437],\n",
      "        [-0.3491],\n",
      "        [-0.2504],\n",
      "        [-0.1487],\n",
      "        [-0.0454],\n",
      "        [ 0.0582],\n",
      "        [ 0.1608],\n",
      "        [ 0.2610],\n",
      "        [ 0.3578],\n",
      "        [ 0.4501],\n",
      "        [ 0.5371],\n",
      "        [ 0.6181],\n",
      "        [ 0.6923],\n",
      "        [ 0.7593],\n",
      "        [ 0.8186],\n",
      "        [ 0.8699],\n",
      "        [ 0.9128],\n",
      "        [ 0.9472],\n",
      "        [ 0.9727],\n",
      "        [ 0.9893],\n",
      "        [ 0.9967],\n",
      "        [ 0.9948],\n",
      "        [ 0.9835],\n",
      "        [ 0.9628],\n",
      "        [ 0.9328],\n",
      "        [ 0.8934],\n",
      "        [ 0.8448],\n",
      "        [ 0.7873],\n",
      "        [ 0.7213],\n",
      "        [ 0.6472],\n",
      "        [ 0.5658],\n",
      "        [ 0.4780],\n",
      "        [ 0.3847],\n",
      "        [ 0.2871],\n",
      "        [ 0.1865],\n",
      "        [ 0.0841],\n",
      "        [-0.0186],\n",
      "        [-0.1204],\n",
      "        [-0.2202],\n",
      "        [-0.3167],\n",
      "        [-0.4091],\n",
      "        [-0.4965],\n",
      "        [-0.5782],\n",
      "        [-0.6538],\n",
      "        [-0.7226],\n",
      "        [-0.7842],\n",
      "        [-0.8383],\n",
      "        [-0.8845],\n",
      "        [-0.9224],\n",
      "        [-0.9518],\n",
      "        [-0.9724],\n",
      "        [-0.9841],\n",
      "        [-0.9866],\n",
      "        [-0.9798],\n",
      "        [-0.9636],\n",
      "        [-0.9382],\n",
      "        [-0.9033],\n",
      "        [-0.8594],\n",
      "        [-0.8064],\n",
      "        [-0.7447],\n",
      "        [-0.6749],\n",
      "        [-0.5973],\n",
      "        [-0.5129],\n",
      "        [-0.4223],\n",
      "        [-0.3266],\n",
      "        [-0.2271],\n",
      "        [-0.1249],\n",
      "        [-0.0214],\n",
      "        [ 0.0821],\n",
      "        [ 0.1842],\n",
      "        [ 0.2837],\n",
      "        [ 0.3796],\n",
      "        [ 0.4707],\n",
      "        [ 0.5564],\n",
      "        [ 0.6358],\n",
      "        [ 0.7084],\n",
      "        [ 0.7737],\n",
      "        [ 0.8312],\n",
      "        [ 0.8806],\n",
      "        [ 0.9216],\n",
      "        [ 0.9539],\n",
      "        [ 0.9774],\n",
      "        [ 0.9918],\n",
      "        [ 0.9970],\n",
      "        [ 0.9930],\n",
      "        [ 0.9796],\n",
      "        [ 0.9567],\n",
      "        [ 0.9245],\n",
      "        [ 0.8830],\n",
      "        [ 0.8323],\n",
      "        [ 0.7728],\n",
      "        [ 0.7048],\n",
      "        [ 0.6290],\n",
      "        [ 0.5461],\n",
      "        [ 0.4569],\n",
      "        [ 0.3625],\n",
      "        [ 0.2641],\n",
      "        [ 0.1630],\n",
      "        [ 0.0604],\n",
      "        [-0.0422],\n",
      "        [-0.1437],\n",
      "        [-0.2428],\n",
      "        [-0.3384],\n",
      "        [-0.4297],\n",
      "        [-0.5159],\n",
      "        [-0.5963],\n",
      "        [-0.6703],\n",
      "        [-0.7375],\n",
      "        [-0.7974],\n",
      "        [-0.8497],\n",
      "        [-0.8940],\n",
      "        [-0.9300],\n",
      "        [-0.9574],\n",
      "        [-0.9759],\n",
      "        [-0.9855],\n",
      "        [-0.9858],\n",
      "        [-0.9769],\n",
      "        [-0.9586],\n",
      "        [-0.9309],\n",
      "        [-0.8940],\n",
      "        [-0.8479],\n",
      "        [-0.7929],\n",
      "        [-0.7293],\n",
      "        [-0.6576],\n",
      "        [-0.5784],\n",
      "        [-0.4924],\n",
      "        [-0.4006],\n",
      "        [-0.3040],\n",
      "        [-0.2037],\n",
      "        [-0.1011],\n",
      "        [ 0.0025],\n",
      "        [ 0.1058],\n",
      "        [ 0.2074],\n",
      "        [ 0.3062],\n",
      "        [ 0.4011],\n",
      "        [ 0.4910],\n",
      "        [ 0.5753],\n",
      "        [ 0.6532],\n",
      "        [ 0.7241],\n",
      "        [ 0.7876],\n",
      "        [ 0.8433],\n",
      "        [ 0.8908],\n",
      "        [ 0.9298],\n",
      "        [ 0.9601],\n",
      "        [ 0.9815],\n",
      "        [ 0.9938],\n",
      "        [ 0.9969],\n",
      "        [ 0.9907],\n",
      "        [ 0.9751],\n",
      "        [ 0.9501],\n",
      "        [ 0.9157],\n",
      "        [ 0.8721],\n",
      "        [ 0.8193],\n",
      "        [ 0.7578],\n",
      "        [ 0.6880],\n",
      "        [ 0.6105],\n",
      "        [ 0.5260],\n",
      "        [ 0.4355],\n",
      "        [ 0.3401],\n",
      "        [ 0.2409],\n",
      "        [ 0.1393],\n",
      "        [ 0.0367],\n",
      "        [-0.0658],\n",
      "        [-0.1668],\n",
      "        [-0.2652],\n",
      "        [-0.3599],\n",
      "        [-0.4501],\n",
      "        [-0.5350],\n",
      "        [-0.6140],\n",
      "        [-0.6864],\n",
      "        [-0.7520],\n",
      "        [-0.8102],\n",
      "        [-0.8607],\n",
      "        [-0.9031],\n",
      "        [-0.9371],\n",
      "        [-0.9624],\n",
      "        [-0.9789],\n",
      "        [-0.9864],\n",
      "        [-0.9846],\n",
      "        [-0.9735],\n",
      "        [-0.9530],\n",
      "        [-0.9232],\n",
      "        [-0.8842],\n",
      "        [-0.8360],\n",
      "        [-0.7790],\n",
      "        [-0.7135],\n",
      "        [-0.6400],\n",
      "        [-0.5591],\n",
      "        [-0.4717],\n",
      "        [-0.3787],\n",
      "        [-0.2811],\n",
      "        [-0.1801],\n",
      "        [-0.0772],\n",
      "        [ 0.0265],\n",
      "        [ 0.1295],\n",
      "        [ 0.2306],\n",
      "        [ 0.3285],\n",
      "        [ 0.4223],\n",
      "        [ 0.5110],\n",
      "        [ 0.5939],\n",
      "        [ 0.6702],\n",
      "        [ 0.7395],\n",
      "        [ 0.8012],\n",
      "        [ 0.8550],\n",
      "        [ 0.9006],\n",
      "        [ 0.9376],\n",
      "        [ 0.9659],\n",
      "        [ 0.9852],\n",
      "        [ 0.9954],\n",
      "        [ 0.9963],\n",
      "        [ 0.9880],\n",
      "        [ 0.9702],\n",
      "        [ 0.9430],\n",
      "        [ 0.9065],\n",
      "        [ 0.8607],\n",
      "        [ 0.8059],\n",
      "        [ 0.7424],\n",
      "        [ 0.6708],\n",
      "        [ 0.5916],\n",
      "        [ 0.5056],\n",
      "        [ 0.4139],\n",
      "        [ 0.3175],\n",
      "        [ 0.2176],\n",
      "        [ 0.1157],\n",
      "        [ 0.0129],\n",
      "        [-0.0893],\n",
      "        [-0.1898],\n",
      "        [-0.2874],\n",
      "        [-0.3812],\n",
      "        [-0.4702],\n",
      "        [-0.5538],\n",
      "        [-0.6313],\n",
      "        [-0.7022],\n",
      "        [-0.7661],\n",
      "        [-0.8225],\n",
      "        [-0.8712],\n",
      "        [-0.9117],\n",
      "        [-0.9437],\n",
      "        [-0.9671],\n",
      "        [-0.9815],\n",
      "        [-0.9868],\n",
      "        [-0.9829],\n",
      "        [-0.9696],\n",
      "        [-0.9470],\n",
      "        [-0.9150],\n",
      "        [-0.8738],\n",
      "        [-0.8236],\n",
      "        [-0.7646],\n",
      "        [-0.6972],\n",
      "        [-0.6219],\n",
      "        [-0.5395],\n",
      "        [-0.4507],\n",
      "        [-0.3565],\n",
      "        [-0.2580],\n",
      "        [-0.1565],\n",
      "        [-0.0532],\n",
      "        [ 0.0504],\n",
      "        [ 0.1530],\n",
      "        [ 0.2535],\n",
      "        [ 0.3506],\n",
      "        [ 0.4433],\n",
      "        [ 0.5307],\n",
      "        [ 0.6121],\n",
      "        [ 0.6869],\n",
      "        [ 0.7544],\n",
      "        [ 0.8143],\n",
      "        [ 0.8663],\n",
      "        [ 0.9099],\n",
      "        [ 0.9449],\n",
      "        [ 0.9711],\n",
      "        [ 0.9883],\n",
      "        [ 0.9964],\n",
      "        [ 0.9952],\n",
      "        [ 0.9847],\n",
      "        [ 0.9647],\n",
      "        [ 0.9354],\n",
      "        [ 0.8967],\n",
      "        [ 0.8488],\n",
      "        [ 0.7920],\n",
      "        [ 0.7266],\n",
      "        [ 0.6531],\n",
      "        [ 0.5723],\n",
      "        [ 0.4849],\n",
      "        [ 0.3920],\n",
      "        [ 0.2947],\n",
      "        [ 0.1942],\n",
      "        [ 0.0920],\n",
      "        [-0.0108],\n",
      "        [-0.1127],\n",
      "        [-0.2127],\n",
      "        [-0.3095],\n",
      "        [-0.4022],\n",
      "        [-0.4900],\n",
      "        [-0.5722],\n",
      "        [-0.6483],\n",
      "        [-0.7176],\n",
      "        [-0.7798],\n",
      "        [-0.8345],\n",
      "        [-0.8813],\n",
      "        [-0.9198],\n",
      "        [-0.9499],\n",
      "        [-0.9712],\n",
      "        [-0.9835],\n",
      "        [-0.9867],\n",
      "        [-0.9806],\n",
      "        [-0.9652],\n",
      "        [-0.9404],\n",
      "        [-0.9063],\n",
      "        [-0.8630],\n",
      "        [-0.8107],\n",
      "        [-0.7497],\n",
      "        [-0.6805],\n",
      "        [-0.6035],\n",
      "        [-0.5195]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 77.,  97.,  88.,  ..., 112., 111., 140.])\n"
     ]
    }
   ],
   "source": [
    "print(trainY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
